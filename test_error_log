2019-10-23 18:35:51,384 scene_graph_generation.inference INFO: inference on batch 14380/26446...
2019-10-23 18:36:05,364 scene_graph_generation.inference INFO: inference on batch 14390/26446...
2019-10-23 18:36:13,676 scene_graph_generation.inference INFO: inference on batch 14400/26446...
2019-10-23 18:36:25,067 scene_graph_generation.inference INFO: inference on batch 14410/26446...
2019-10-23 18:36:38,469 scene_graph_generation.inference INFO: inference on batch 14420/26446...
2019-10-23 18:36:52,184 scene_graph_generation.inference INFO: inference on batch 14430/26446...
2019-10-23 18:37:02,847 scene_graph_generation.inference INFO: inference on batch 14440/26446...
2019-10-23 18:37:19,755 scene_graph_generation.inference INFO: inference on batch 14450/26446...
2019-10-23 18:37:30,887 scene_graph_generation.inference INFO: inference on batch 14460/26446...
2019-10-23 18:37:40,194 scene_graph_generation.inference INFO: inference on batch 14470/26446...
2019-10-23 18:37:52,216 scene_graph_generation.inference INFO: inference on batch 14480/26446...
2019-10-23 18:38:06,958 scene_graph_generation.inference INFO: inference on batch 14490/26446...
2019-10-23 18:38:20,020 scene_graph_generation.inference INFO: inference on batch 14500/26446...
2019-10-23 18:38:33,100 scene_graph_generation.inference INFO: inference on batch 14510/26446...
2019-10-23 18:38:44,154 scene_graph_generation.inference INFO: inference on batch 14520/26446...
2019-10-23 18:38:56,339 scene_graph_generation.inference INFO: inference on batch 14530/26446...
2019-10-23 18:39:09,630 scene_graph_generation.inference INFO: inference on batch 14540/26446...
2019-10-23 18:39:21,710 scene_graph_generation.inference INFO: inference on batch 14550/26446...
2019-10-23 18:39:35,966 scene_graph_generation.inference INFO: inference on batch 14560/26446...
2019-10-23 18:39:48,136 scene_graph_generation.inference INFO: inference on batch 14570/26446...
2019-10-23 18:39:55,803 scene_graph_generation.inference INFO: inference on batch 14580/26446...
2019-10-23 18:40:05,107 scene_graph_generation.inference INFO: inference on batch 14590/26446...
2019-10-23 18:40:18,396 scene_graph_generation.inference INFO: inference on batch 14600/26446...
2019-10-23 18:40:35,119 scene_graph_generation.inference INFO: inference on batch 14610/26446...
2019-10-23 18:40:46,960 scene_graph_generation.inference INFO: inference on batch 14620/26446...
2019-10-23 18:40:59,945 scene_graph_generation.inference INFO: inference on batch 14630/26446...
2019-10-23 18:41:11,828 scene_graph_generation.inference INFO: inference on batch 14640/26446...
2019-10-23 18:41:23,077 scene_graph_generation.inference INFO: inference on batch 14650/26446...
2019-10-23 18:41:34,323 scene_graph_generation.inference INFO: inference on batch 14660/26446...
2019-10-23 18:41:46,060 scene_graph_generation.inference INFO: inference on batch 14670/26446...
2019-10-23 18:42:01,093 scene_graph_generation.inference INFO: inference on batch 14680/26446...
2019-10-23 18:42:10,035 scene_graph_generation.inference INFO: inference on batch 14690/26446...
2019-10-23 18:42:18,191 scene_graph_generation.inference INFO: inference on batch 14700/26446...
2019-10-23 18:42:27,048 scene_graph_generation.inference INFO: inference on batch 14710/26446...
2019-10-23 18:42:37,947 scene_graph_generation.inference INFO: inference on batch 14720/26446...
2019-10-23 18:42:51,398 scene_graph_generation.inference INFO: inference on batch 14730/26446...
2019-10-23 18:43:00,417 scene_graph_generation.inference INFO: inference on batch 14740/26446...
2019-10-23 18:43:13,767 scene_graph_generation.inference INFO: inference on batch 14750/26446...
2019-10-23 18:43:28,245 scene_graph_generation.inference INFO: inference on batch 14760/26446...
2019-10-23 18:43:39,083 scene_graph_generation.inference INFO: inference on batch 14770/26446...
2019-10-23 18:43:54,235 scene_graph_generation.inference INFO: inference on batch 14780/26446...
2019-10-23 18:44:10,221 scene_graph_generation.inference INFO: inference on batch 14790/26446...
2019-10-23 18:44:19,334 scene_graph_generation.inference INFO: inference on batch 14800/26446...
2019-10-23 18:44:30,271 scene_graph_generation.inference INFO: inference on batch 14810/26446...
2019-10-23 18:44:39,381 scene_graph_generation.inference INFO: inference on batch 14820/26446...
2019-10-23 18:44:50,935 scene_graph_generation.inference INFO: inference on batch 14830/26446...
2019-10-23 18:45:03,235 scene_graph_generation.inference INFO: inference on batch 14840/26446...
2019-10-23 18:45:14,425 scene_graph_generation.inference INFO: inference on batch 14850/26446...
2019-10-23 18:45:25,497 scene_graph_generation.inference INFO: inference on batch 14860/26446...
2019-10-23 18:45:40,379 scene_graph_generation.inference INFO: inference on batch 14870/26446...
2019-10-23 18:45:58,021 scene_graph_generation.inference INFO: inference on batch 14880/26446...
2019-10-23 18:46:09,676 scene_graph_generation.inference INFO: inference on batch 14890/26446...
2019-10-23 18:46:27,455 scene_graph_generation.inference INFO: inference on batch 14900/26446...
2019-10-23 18:46:42,926 scene_graph_generation.inference INFO: inference on batch 14910/26446...
2019-10-23 18:46:58,804 scene_graph_generation.inference INFO: inference on batch 14920/26446...
2019-10-23 18:47:08,610 scene_graph_generation.inference INFO: inference on batch 14930/26446...
2019-10-23 18:47:19,578 scene_graph_generation.inference INFO: inference on batch 14940/26446...
2019-10-23 18:47:33,841 scene_graph_generation.inference INFO: inference on batch 14950/26446...
2019-10-23 18:47:44,561 scene_graph_generation.inference INFO: inference on batch 14960/26446...
2019-10-23 18:48:00,255 scene_graph_generation.inference INFO: inference on batch 14970/26446...
2019-10-23 18:48:12,019 scene_graph_generation.inference INFO: inference on batch 14980/26446...
2019-10-23 18:48:23,170 scene_graph_generation.inference INFO: inference on batch 14990/26446...
2019-10-23 18:48:35,657 scene_graph_generation.inference INFO: inference on batch 15000/26446...
2019-10-23 18:48:45,692 scene_graph_generation.inference INFO: inference on batch 15010/26446...
2019-10-23 18:48:59,604 scene_graph_generation.inference INFO: inference on batch 15020/26446...
2019-10-23 18:49:07,597 scene_graph_generation.inference INFO: inference on batch 15030/26446...
2019-10-23 18:49:16,190 scene_graph_generation.inference INFO: inference on batch 15040/26446...
Traceback (most recent call last):
  File "main.py", line 130, in <module>
    main()
  File "main.py", line 127, in main
    test(cfg, args)
  File "main.py", line 80, in test
    model.test(visualize=args.visualize)
  File "/home/ailab/gy/graph-rcnn.pytorch/lib/model.py", line 240, in test
Traceback (most recent call last):
    output = self.scene_parser(imgs)
  File "/home/ailab/anaconda3/envs/grcn2/lib/python3.6/multiprocessing/queues.py", line 240, in _feed
    send_bytes(obj)
  File "/home/ailab/anaconda3/envs/grcn2/lib/python3.6/site-packages/torch/nn/modules/module.py", line 489, in __call__
  File "/home/ailab/anaconda3/envs/grcn2/lib/python3.6/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/home/ailab/anaconda3/envs/grcn2/lib/python3.6/multiprocessing/connection.py", line 404, in _send_bytes
    self._send(header + buf)
  File "/home/ailab/anaconda3/envs/grcn2/lib/python3.6/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
    result = self.forward(*input, **kwargs)
  File "/home/ailab/gy/graph-rcnn.pytorch/lib/scene_parser/parser.py", line 120, in forward
    x, detections, roi_heads_loss = self.roi_heads(features, proposals, targets)
  File "/home/ailab/anaconda3/envs/grcn2/lib/python3.6/site-packages/torch/nn/modules/module.py", line 489, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/ailab/gy/graph-rcnn.pytorch/lib/scene_parser/rcnn/modeling/roi_heads/roi_heads.py", line 23, in forward
    x, detections, loss_box = self.box(features, proposals, targets)
  File "/home/ailab/anaconda3/envs/grcn2/lib/python3.6/site-packages/torch/nn/modules/module.py", line 489, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/ailab/gy/graph-rcnn.pytorch/lib/scene_parser/rcnn/modeling/roi_heads/box_head/box_head.py", line 58, in forward
    result = self.post_processor((class_logits, box_regression), proposals)
  File "/home/ailab/anaconda3/envs/grcn2/lib/python3.6/site-packages/torch/nn/modules/module.py", line 489, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/ailab/gy/graph-rcnn.pytorch/lib/scene_parser/rcnn/modeling/roi_heads/box_head/inference.py", line 95, in forward
    filtered_boxlist = self.filter_results_nm(boxlist, num_classes)
  File "/home/ailab/gy/graph-rcnn.pytorch/lib/scene_parser/rcnn/modeling/roi_heads/box_head/inference.py", line 196, in filter_results_nm
    valid_cls = (scores[:, 1:].max(0)[0] > thresh).nonzero() + 1
  File "/home/ailab/anaconda3/envs/grcn2/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 274, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 14217) is killed by signal: Killed. 
CUDA_VISIBLE_DEVICES=0 python main.py --config-file configs/sgg_res101_step.yaml --inference --resume 13999 --algorithm sg_grcnn
(grcn2) ailab@ailab:~/gy/graph-rcnn.pytorch$ 

